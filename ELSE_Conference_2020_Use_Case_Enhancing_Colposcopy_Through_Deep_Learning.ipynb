{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ELSE_Conference_2020_Use_Case_Enhancing_Colposcopy_Through_Deep_Learning.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"68ZK63IzNOGk","colab_type":"text"},"source":["# Cervical cancer prevention through colposcopy and deep learning"]},{"cell_type":"markdown","metadata":{"id":"ffsCNnqrsMkt","colab_type":"text"},"source":["## Preliminary steps"]},{"cell_type":"markdown","metadata":{"id":"A_HZoSwTsUoa","colab_type":"text"},"source":["**Before you start using this notebook please enable the free GPU available.** Without it the notebook will not work. For doing so navigate to the menu \"Runtime\" and select \"Change runtime type\". Then enable the GPU from the \"Hardware accelerator\" section. \n","\n","If you are not used to Jupyter notebooks or Google Colab please look into this tutorial before starting:\n","https://colab.research.google.com/notebooks/welcome.ipynb"]},{"cell_type":"markdown","metadata":{"id":"4iGmOuPLPQB4","colab_type":"text"},"source":["## What is a colposcopy"]},{"cell_type":"markdown","metadata":{"id":"1ojseoJ2UURK","colab_type":"text"},"source":["The cervix cancer, or cervical cancer is a very dangerous condition which in most of the cases can be avoided through a simple medical inspection named colposcopy. Colposcopy is a relatively non-invasive procedure which consists in the visual inspection of the cervix after applying an acetic acid solution to it. After the application of the solution, the ill areas of the cervix changes colour becoming whiter, enabling the doctor to better asses the state of the patient. The purpose of the colposcopy is not only to detect cancerous tissues, but especially to detect lesions of the cervix which could degenerate into cancer over time. The lesions are usually named CIN(cervical intraepithelial neoplasia) and are split in three classes: CIN1, CIN2, CIN3, based on their severity. The issue with colposcopy is that it requires highly trained professionals in order to be accurate, i.e., even medical personnel can make mistakes when setting a diagnostic based on colposcopy. Researchers are trying to boost the accuracy of colposcopy so that it surpasses human accuracy."]},{"cell_type":"markdown","metadata":{"id":"N_1SoIUsWeZk","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"938GhnGHWeIQ","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"LBNm1JhlWdwD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5tR2tUYkWdXm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xxf-E4-4Pib-","colab_type":"text"},"source":["## Dataset description"]},{"cell_type":"markdown","metadata":{"id":"36lDYxR0UbR4","colab_type":"text"},"source":["For this case we propose the cervigram image dataset published on IEEE Dataport. The dataset contains 3339 images, from 477 colposcopy procedures; 3003 images belong to the training set and 336 to the validation set. Each colposcopy procedure is represented in the dataset by seven images, five of them are a sequence displaying the transformation of the cervix after applying acetic acid solution. The last two images are different, one of them show the cervix through a green lens, while the other one shows the cervix after applying iodine solution, a solution of a dark red color. For simplicity, in our case, we will focus only on the images involving acetic acid solution. The dataset is aimed at classification problems, the cervical lesions are divided in four categories: class zero(normal cervix), class one(CIN1), class two(CIN2/3) and class three(cervical cancer). "]},{"cell_type":"markdown","metadata":{"id":"PtygCa5YSc-j","colab_type":"text"},"source":["## Acquiring the dataset"]},{"cell_type":"markdown","metadata":{"id":"qGO_l53WUwDP","colab_type":"text"},"source":["The dataset is available at:\n","https://ieee-dataport.org/documents/cervigram-image-dataset\n","\n","You need to sign-up in order to be able to download the dataset. You can also sign-up as a beta tester and get a free subscription. \n","\n","Once you downloaded the dataset you will have a file named \"data.zip\". The simplest way is to upload this file manually in Google Colab. Check out the left side region of the Colab window for uploading the file, you should look for an icon that looks like a folder. This will open up the \"Files\" section. In there, you will notice an \"Upload\" button. Even though it is the most simple way, we **do not recommend** working like this. The upload may be slow and when working on Google Colab you are actually on a virtual machine, which gets wiped out once you disconnect thus, the files will get lost. You would need to do the upload each time you reconnect.\n","\n","A better way of working would be to upload the dataset to your Google Drive. Then, each time you reconnect, you can mount your Google Drive to the Colab environment. The process is simple and will save a lot of time in the long run. In order to mount your Google Drive, you need to run the code below. You should note the mounted drive in the files section of Colab, please check the left side of the window."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"w12ajwYkRYMj","colab":{}},"source":["try:\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","except Exception as e:\n","  print('Are you running in a Google Colab environment ?')\n","  print(e)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4JI_au-9J2Yu","colab_type":"text"},"source":["The script below, clears the dataset folder, then it recreates it. Next, it unzips the dataset into it. In the previous step you either uploaded the file directly from Colab, either to Google Drive, depending on your option please uncomment the relevant line in the script and comment the other. **The path to the file may not match exactly, please modify accordingly.** Once the script finishes please refresh the files view to notice the downloaded files. Inside the dataset folder you should notice a \"data\" folder containing two sub-folders \"train\" and \"test\". Each of those folders contain folders labeled from zero to three, those correspond to each of the classes.\n","\n","**Please note the way to run UNIX commands from Colab, simply put a \"!\" in front of the statement.**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"30WlKBSGZfpq","colab":{}},"source":["!rm -vrf \"dataset\"\n","!mkdir \"dataset\"\n","\n","# If using Google Drive:\n","!cp -r \"/content/drive/My Drive/data.zip\" \"dataset/data.zip\"\n","\n","# If not using Google Drive\n","# !cp -r \"/content/data.zip\" \"dataset/data.zip\"\n","\n","!unzip \"dataset/data.zip\" -d \"dataset\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r0iLIQdWRUe_","colab_type":"text"},"source":["## Download dependencies"]},{"cell_type":"markdown","metadata":{"id":"xyLy4KocUn70","colab_type":"text"},"source":["**pip is the default Python package manager**, it gets installed together with Python. The command below installs the dependencies we need."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-00MlLK5bd_o","colab":{}},"source":["!pip3 install torch torchvision sklearn matplotlib GPUtil"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"G79HqNc8ZaJ8"},"source":["## Constants"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g1YBANp9XJeA","colab":{}},"source":["DATASET_PATH = '/content/dataset/data/'\n","TRAIN_PATH = DATASET_PATH + 'train/'\n","TEST_PATH = DATASET_PATH + 'test/'\n","IMAGE_SIZE = 224\n","BATCH_SIZE = 100\n","LEARNING_RATE = 1e-4\n","EPOCHS = 10"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TATYX0D4Z3yJ","colab_type":"text"},"source":["## Imports"]},{"cell_type":"markdown","metadata":{"id":"D0G9a0ZpbBfN","colab_type":"text"},"source":["We import the packages needed."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qyNuLlPNsdl1","colab":{}},"source":["import torch as t\n","import torchvision as tv\n","import numpy as np\n","import PIL as pil\n","import matplotlib.pyplot as plt\n","import sklearn as sk\n","import sklearn.metrics\n","import os\n","import time\n","import random\n","import GPUtil"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bVU6YiBGfcgj","colab_type":"text"},"source":["## Memory management"]},{"cell_type":"markdown","metadata":{"id":"cRBXAfCOfpHB","colab_type":"text"},"source":["While training neural networks, it's not uncommon for a GPU to run out of memmory. The cell below displays how much memory has each GPU and how much of it is already allocated. If running out of memory you should restart the runtime, if this does not fix the problem please gradually decrease the batch size."]},{"cell_type":"code","metadata":{"id":"T-_qB9dBlFEK","colab_type":"code","colab":{}},"source":["def memory_stats():\n","  count = 1\n","  for gpu in GPUtil.getGPUs():\n","    print('GPU', count, 'Memory')\n","    print('-----------------------')\n","    print('Total:', gpu.memoryTotal)\n","    print('Free:', gpu.memoryFree)\n","    print('Used:', gpu.memoryUsed)\n","    print('Used percent:', gpu.memoryUtil * 100, '%')\n","    print('-----------------------')\n","    count += 1  \n","\n","memory_stats()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"72bTpJMNntOC","colab_type":"text"},"source":["## Deterministic measurements"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bQ3rHF5K2BpX"},"source":["This statements help making the experiments reproducible by fixing the random seeds. Despite fixing the random seeds, experiments are usually not reproducible using different PyTorch releases, commits, platforms or between CPU and GPU executions. Please find more details in the PyTorch documentation:\n","\n","https://pytorch.org/docs/stable/notes/randomness.html"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PQtgx_3H2MEx","colab":{}},"source":["SEED = 0\n","t.manual_seed(SEED)\n","t.cuda.manual_seed(SEED)\n","t.cuda.manual_seed_all(SEED)\n","t.backends.cudnn.deterministic = True\n","t.backends.cudnn.benchmark = False\n","np.random.seed(SEED)\n","random.seed(SEED)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sYPBGvOkqvtw","colab_type":"text"},"source":["## Loading data"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8_PMRn9BcaPO"},"source":["The dataset is structured in multiple small folders of 7 images each. This generator iterates through the folders and returns the category and 7 paths: one for each image in the folder. The paths are ordered; the order is important since each folder contains 3 types of images, first 5 are with acetic acid solution and the last two are through a green lens and having iodine solution(a solution of a dark red color). In our case we will work only with the first 5 images(with acetic acid). Taking advantage of the rest of images is left as an open question/exercise to the reader.\n","\n","Please note the yield statement in the second function, this turns the function in a Python generator. If you are not aware of what a Python generator is please read this resource:\n","https://wiki.python.org/moin/Generators "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qU2qOUVWZZNl","colab":{}},"source":["def sortByLastDigits(elem):\n","  chars = [c for c in elem if c.isdigit()]\n","  return 0 if len(chars) == 0 else int(''.join(chars))\n","\n","def getImagesPaths(root_path):\n","  for class_folder in [root_path + f for f in os.listdir(root_path)]:\n","      category = int(class_folder[-1])\n","      for case_folder in os.listdir(class_folder):\n","        case_folder_path = class_folder + '/' + case_folder + '/'\n","        img_files = [case_folder_path + file_name for file_name in os.listdir(case_folder_path)]\n","        yield category, sorted(img_files, key = sortByLastDigits)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MSrKoW7TdRFr"},"source":["We define a dataset which can apply dynamic and static transformations to images. The static transformations are applied on the initialization of the dataset, while the dynamic ones are applied every time when loading a batch of images.\n","\n","Defining a dataset requires us to extend a PyTorch class \"torch.utils.data.Dataset\" and overwrite the methods __getitem__ and __len__. For more details please view this interesting tutorial from the PyTorch documentation: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EmgWK_7-doGb","colab":{}},"source":["class SimpleImagesDataset(t.utils.data.Dataset):\n","  def __init__(self, root_path, transforms_x_static = None, transforms_x_dynamic = None, transforms_y_static = None, transforms_y_dynamic = None):\n","    self.dataset = []\n","    self.transforms_x = transforms_x_dynamic\n","    self.transforms_y = transforms_y_dynamic\n","    for category, img_files in getImagesPaths(root_path):\n","      # We use only the first 5 images which correspond to images with acetic acid solution\n","      for i in range(5):\n","        # The PIL library is one of the most popular solutions for processing images in Python\n","        img = pil.Image.open(img_files[i])\n","        # Static transforms are applied on dataset initialization\n","        if transforms_x_static != None:\n","          img = transforms_x_static(img)\n","        if transforms_y_static != None:\n","          category = transforms_y_static(category)\n","        self.dataset.append((img, category))    \n","  \n","  def __getitem__(self, i):\n","    x, y = self.dataset[i]\n","    # Dynamic transformations are applied every time images load\n","    if self.transforms_x != None:\n","      x = self.transforms_x(x)\n","    if self.transforms_y != None:\n","      y = self.transforms_y(y)\n","    return x, y\n","\n","  def __len__(self):\n","    return len(self.dataset)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3dA54bK3XEHg","colab_type":"text"},"source":["## Data augmentation"]},{"cell_type":"markdown","metadata":{"id":"ejvcydwlfURp","colab_type":"text"},"source":["Neural networks work best when presented to vast amounts of data. For a computer vision task, the dataset we use can be considered small. In order to mitigate reduced training sets we can use image augmentation. This technique creates new training samples from existing ones by applying different transformations to the images, such as deformations, swiping the images vertically or horizontally, zoom, and color variations."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TmnrMN5BmHRg"},"source":["Data transformations for the test and training sets."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_hBCnG-fvwjB","colab":{}},"source":["norm_mean = [0.485, 0.456, 0.406]\n","norm_std = [0.229, 0.224, 0.225]\n","\n","# input transformation for training set\n","transforms_train = tv.transforms.Compose([\n","    # performs rotation between 0 and 45 degrees, scaling between 100% to 200% and shear deformation between 0 and 30 degrees                                    \n","    tv.transforms.RandomAffine(degrees  = 45, translate = None, scale = (1., 2.), shear = 30),  \n","    # resizes the image\n","    tv.transforms.Resize(IMAGE_SIZE),\n","    # flips the image horizontally with a 1/2 probability\n","    tv.transforms.RandomHorizontalFlip(),\n","    # turns the image which is in PIL format to PyTorch tensor\n","    tv.transforms.ToTensor(),\n","    # a custom defined transformation for placing the tensor on the GPU, the tensor is on CPU by default\n","    tv.transforms.Lambda(lambda t: t.cuda()),\n","    # performs normalization by subtracting the mean and dividing with the standard deviation, both have 3 elements since there are 3 channels for RGB(red, green, blue)\n","    tv.transforms.Normalize(mean=norm_mean, std=norm_std)    \n","])\n","\n","# input transformation for test set\n","transforms_test = tv.transforms.Compose([\n","    # resizes the image\n","    tv.transforms.Resize(IMAGE_SIZE),\n","    # turns the image which is in PIL format to PyTorch tensor\n","    tv.transforms.ToTensor(),\n","    # performs normalization by subtracting the mean and dividing with the standard deviation, both have 3 elements since there are 3 channels for RGB(red, green, blue)\n","    tv.transforms.Normalize(mean=norm_mean, std=norm_std)    \n","])\n","\n","# output transformation of test set, transforms y into a PyTorch tensor of type long and places it on the GPU named 'cuda:0'\n","y_transform = tv.transforms.Lambda(lambda y: t.tensor(y, dtype=t.long, device = 'cuda:0'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5ky8gX31q-NW"},"source":["The dataset and a dataset loader are two different things in PyTorch. The dataset, represent the data itself, while the loader batches the data and performs data augmentation(applies certain transforms for data variety). Furthermore, we can choose to shuffle the data at train time, preventing the network from learning fixed patterns, data shuffling is not needed for network testing(evaluation)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2hqOyTVGnjjy","colab":{}},"source":["dataset_train = SimpleImagesDataset(TRAIN_PATH, transforms_x_dynamic = transforms_train, transforms_y_dynamic = y_transform)\n","dataset_test = SimpleImagesDataset(TEST_PATH, transforms_x_static = transforms_test, transforms_x_dynamic = tv.transforms.Lambda(lambda t: t.cuda()), transforms_y_dynamic = y_transform)\n","\n","# We will need len_tain and len_test later, they express the number of images in the train and test dataset\n","len_train, len_test = len(dataset_train), len(dataset_test)\n","print('Training set contains {} samples and test set contains {} samples.'.format(len_train, len_test))\n","\n","loader_train = t.utils.data.DataLoader(dataset_train, BATCH_SIZE, shuffle = True, num_workers = 0)\n","loader_test = t.utils.data.DataLoader(dataset_test, BATCH_SIZE, shuffle = False, num_workers = 0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cYi9sETng_G4","colab_type":"text"},"source":["## Visualize data"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UOI_JvcCe0cR"},"source":["Utility function to convert PyTorch tensor to Numpy array. Numpy is probably the most popular Python package for tensor handling and mathematical computing, forming around itself a whole ecosystem, please find our more at the Numpy homepage: https://numpy.org/ "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OKxTUFnkezdb","colab":{}},"source":["# places the tensor on cpu, it detaches it from gradient computation and then transforms it to numpy array\n","def to_numpy(x):\n","  return x.cpu().detach().numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F5tbFIZYjsOl","colab_type":"text"},"source":["Functions for plotting one and several images. Please note the usage of matplotlib, one of the most advanced plotting libraries in Python, with endless possibilities."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mDi25EAxrSal","colab":{}},"source":["def plot_one_prediction(x, label):  \n","  # transform to numpy arrays\n","  x, label = to_numpy(x), to_numpy(label)\n","  # matplotlib imshow function expects image format having the channels as a last dimension, \n","  # while our network expects the image channels as a first dimension \n","  x = np.transpose(x, [1, 2, 0])\n","  # the image tensors are normalized, we need to undo this transformation\n","  # x, norm_std and norm_mean are not scalars, are tensors, please note the operators broadcasting to the tensors\n","  # please find more at: https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html\n","  x = x * np.array(norm_std) + np.array(norm_mean)\n","  # set plot title and plot image\n","  plt.title(label)\n","  plt.imshow(x)\n","\n","# compose a single plot out of multiple plots, we will obtain a 4 x 5 images matrix\n","def plot_predictions(imgs, labels):  \n","  fig = plt.figure(figsize = (20, 10))\n","  for i in range(20):\n","    fig.add_subplot(4, 5, i + 1, xticks = [], yticks = [])\n","    plot_one_prediction(imgs[i], labels[i])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ARRQsL2drbzv"},"source":["Load a few images from the training set, so that we can visualize the effects of data augmentation."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Q0jkeNIVrVf3","colab":{}},"source":["# load images and ground truth labels\n","x, y = next(iter(loader_train))\n","# plot images\n","plot_predictions(x, y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kFqstEcXxuIz","colab_type":"text"},"source":["## Define the model"]},{"cell_type":"markdown","metadata":{"id":"NbB-ea3xyI4p","colab_type":"text"},"source":["We will be using a ResNet model having 18 layers, pretrained on ImageNet.\n","\n","Please learn more about this architecture by reading this paper:\n","https://arxiv.org/abs/1512.03385\n","\n","Also please check out the torch vision documentation of the models available:\n","https://pytorch.org/docs/stable/torchvision/models.html\n","\n","Please try to experiment with other models as well."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3rQm0JTXsLOO","colab":{}},"source":["def get_resnet_18():\n","  # download the model\n","  model = tv.models.resnet18(pretrained = True)\n","  # the model is pretrained on ImageNet which is a 1000 classification problem, we change the last layer of the network in order to clasify only 4 classes\n","  model.fc.out_features = 4\n","  # we place the model on the GPU\n","  model = model.cuda()\n","  return model\n","\n","# t.nn.DataParrallel trains the model on multiple GPU if available, if not it trains on a single one\n","model = t.nn.DataParallel(get_resnet_18())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GyGhrKmq0S_y","colab_type":"text"},"source":["## Train & evaluate"]},{"cell_type":"markdown","metadata":{"id":"FB0BUs2hDjOe","colab_type":"text"},"source":["This class defines the metrics to be recorded during training."]},{"cell_type":"code","metadata":{"id":"hw52957SDoLN","colab_type":"code","colab":{}},"source":["class Metrics:\n","  # define the constructor\n","  def __init__(self):\n","    self.loss = 0\n","    self.accuracy = 0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AaK0kaZU6Mcv","colab_type":"text"},"source":["In our case we will train the network in a supervised manner. Supervised training requires the network prediction and the expected result, which is usually called \"ground truth\". The error is calculated by a loss function which receives as parameters the tensors representing the ground truth and the network prediction. The loss function outputs a scalar value for each training sample, representing the magnitude of the error. In order to make the network learn, we differentiate the loss value with respect to each network parameter (which is a tensor). This implies that the whole network, including the loss function need to be a sequence of differentiable operations. Software implementations make our lives very easy, because they implement the differentiation in an automatic way, by building a computational graph, in which each node represent an operation and each vertex the resulting tensor. Each node (operation) has associated its specific differentiation function. By exploiting the chain rule, each operation (starting from the loss function) is differentiated with respect to its tensors, and those are differentiated recursively with respect to their parent tensors until the differentiation chain reaches the network parameters. Next, each parameter of the network is updated by the negative value of the calculated gradient (derivative of the loss with respect to a network parameter) multiplied by a small number named learning rate. Typically values for the learning rate are between 1e-3 to 1e-5. The learning rate assures proper convergence of the algorithm and its value is crucial in the process of training. After each update of parameters, the network makes the loss value smaller and smaller, thus training of a neural network implies minimizing the loss function with respect to the network parameters. The update of network parameters using the gradients and the learning rate is handled by the optimizer object defined below. The calculation of the network prediction and loss form the forward pass of the network, the calculation of gradients(derivatives of loss with respect to network parameters) forms the backward pass."]},{"cell_type":"code","metadata":{"id":"VdXH0IYikxPR","colab_type":"code","colab":{}},"source":["loss_fn = t.nn.CrossEntropyLoss()\n","optimizer = t.optim.Adam(model.parameters(), lr = LEARNING_RATE, weight_decay = 0)\n","\n","# This function performs a forward pass of the network and records the metrics. \n","# If training is ebabled, a backword pass and network parameter updates are also performed.\n","def run_network(loader, len_dataset, isTrain):  \n","  # In Python we need to explicitly mark variables which came from outside of a function\n","  global model, optimizer, loss_fn\n","  metrics = Metrics()\n","\n","  # Iterate through the dataset using the data loader\n","  for x, y in loader:\n","    # Network forward pass\n","    y_pred = model.forward(x)\n","    # Calculate loss value\n","    loss = loss_fn(y_pred, y)\n","    \n","    # Backword pass\n","    if isTrain:\n","      assert optimizer != None\n","      # Gradient backwords propagation \n","      loss.backward()\n","      # Network parameter updates\n","      optimizer.step()\n","      # Refresh optimizer state\n","      optimizer.zero_grad()\n","    \n","    # Calculate prediction: y_pred is a batch of arrays of probabilities, \n","    # the predicted classes(variable pred) are found by recording the indexes \n","    # corresponding to the biggest probabilities in the arrays from y_pred\n","    y_pred, y = to_numpy(y_pred), to_numpy(y)\n","    pred = y_pred.argmax(axis = 1)\n","    \n","    # The last batch have fewer elements then the rest. \n","    # For this reason we weight each metric by the population size of the batch using the variable named 'ratio'\n","    ratio = len(y) / len_dataset\n","    metrics.loss += (loss.item() * ratio)\n","    metrics.accuracy += (sk.metrics.accuracy_score(y, pred) * ratio)\n","  return metrics"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2ZE3UqwMvbfM"},"source":["The training happens in a loop, for a certain number of iterations, also named epochs. For each epoch, we go through the whole training dataset and evaluate the model on the test set. We record the metrics for both training set and test set. If the accuracy on the test set is bigger then in the previous rounds we save a checkpoint of the model(we serialize the model). This way, at the end of the training, we are left with a checkpoint of the model that recorded the best accuracy on the test set.\n","\n","Please check out this PyTorch tutorial for further details about model saving and loading: https://pytorch.org/tutorials/beginner/saving_loading_models.html"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FwUA4abu2pRe","colab":{}},"source":["# We'll store the metrics per each epoch for plotting\n","metrics_train_per_epochs, metrics_test_per_epochs = [], []\n","# If testing on a certain epoch yields better accuracy, then we checkpoint the model\n","best_acc = 0\n","    \n","try:  \n","  for epoch in range(EPOCHS):    \n","    # Train\n","    # We enable the train mode on the model, this activates all dropout and batch normalization layers\n","    model.train()\n","    train_metrics = run_network(loader_train, len_train, isTrain = True)\n","    metrics_train_per_epochs.append(train_metrics)\n","    \n","    # Evaluate\n","    # We enable evaluation mode on the model, this disables all dropout and batch normalization layers\n","    model.eval()\n","    # During testing we do not calculate any gradients, nor perform any network parameter updates\n","    with t.no_grad():\n","      test_metrics = run_network(loader_test, len_test, isTrain = False)\n","      metrics_test_per_epochs.append(test_metrics)\n","      \n","    # We save a model chekpoint if we find any improvement  \n","    if test_metrics.accuracy > best_acc:\n","      best_acc = test_metrics.accuracy\n","      t.save({'model': model.state_dict()}, 'model checkpoint.tar')\n","\n","    # Logging  \n","    print('Epoch {} accuracy {}'.format(epoch + 1, test_metrics.accuracy))\n","\n","except KeyboardInterrupt as e:\n","  print('Training interrupted at epoch', epoch)  \n","print('Ended training')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EvzF5UW7jpJt","colab_type":"text"},"source":["## Visualize results"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BPznZeFDxhtA"},"source":["Plot a metric per epochs for both train and test data sets."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4QjYASRPRnIr","colab":{}},"source":["def plot_train_test(train, test, title, y_title):\n","    plt.plot(range(len(train)), train, label = 'train')\n","    plt.plot(range(len(test)), test, label = 'test')\n","    plt.xlabel('Epochs')\n","    plt.ylabel(y_title)\n","    plt.title(title)\n","    plt.legend()\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k5y8rOEn6Q-v","colab_type":"text"},"source":["Perform actual plotting."]},{"cell_type":"code","metadata":{"id":"CK8OGDhhj5vH","colab_type":"code","colab":{}},"source":["test_accuracies = list(map(lambda m: m.accuracy, metrics_test_per_epochs))\n","test_loss = list(map(lambda m: m.loss, metrics_test_per_epochs))\n","train_accuracies = list(map(lambda m: m.accuracy, metrics_train_per_epochs))\n","train_loss = list(map(lambda m: m.accuracy, metrics_train_per_epochs))\n","\n","index_max = np.array(test_accuracies).argmax()\n","print('Best test accuracy :', test_accuracies[index_max])\n","\n","plot_train_test(train_loss, test_loss, 'Loss', 'Loss')\n","plot_train_test(train_accuracies, test_accuracies, 'Accuracy', 'Accuracy')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z2bgblbW6chH","colab_type":"text"},"source":["## Open questions"]},{"cell_type":"markdown","metadata":{"id":"cYpXSlnl-Edb","colab_type":"text"},"source":["Improving colposcopy through deep learning is an active research area. Here are a few open questions, to spark your curiosity:\n","\n","**1)** How could we take advantage of the rest of the images, taken through the green lens and with iodine solution ?\n","\n","**2)** The dataset is unbalanced, how can we counter this phenomenon if we are not able to find additional data ? \n","\n","**3)** The model seems to overfit easily while training, how can we counter this ?\n","\n","**4)** What other architectures and methods can be applied to better model this problem, just a few ideas: ensembles, recurrent networks, object localization, additional image preprocessing, multi-scale convolutions ?  \n","\n","The questions above cover many possibilities and does not have a precise answer. Deep learning is a field of programming where a problem can be solved in more then one way. Both knowledge and creativity can play an important role. "]}]}